# 概率与期望

## 期望的性质

期望观察取值的范围，是取值范围的一个平均值。有些概率题会用到该性质。

线性性：某个复合事件的期望=若干个拆分事件的期望。虽然拆分事件彼此不要求独立，但在做题目时将复合事件拆分成彼此独立的子事件来做，一般这种子事件的期望易求。

## 恰好的概率

$P(X=K)=P(X>=K)-P(X>K)$。相容减。

### 最大值不超过k的关于最大值的期望

$[1,n]$ 随机 $m$ 次，结果 $=\sum\limits_{i=1}^{k}i*P(X=i)$

其中

$P(X=i)=P(X<=i) - P(X<=i-1) = (\frac{i}{n})^m - (\frac{i-1}{n})^m$​

## 概率为p成功的次数期望

其实就是几何分布成功一次的期望：$\frac{1}{p}$。原理基于无穷级数为等比数列，转化一下得出结果。

突然想到几何分布的无后效性 + 期望的线性性 $\Rightarrow$ ​成功 $n$ ​次的次数期望：$\frac{n}{p}$​​。

## 基础问题

### 编号1~n的球取m次的编号和期望

编号为 $1\sim n$​ 的球，取 m 次不放回，问取出来的球编号之和的期望。

$\frac{m(n+1)}{2}$

证明：考虑有顺序无放回（抽奖原则）。比如第 $i$ ​次取到数字 2 的概率：$\frac{n-1}{n}*\frac{n-2}{n-1}*...*\frac{n-i+1}{n-i+2}*\frac{1}{n-i+1}=\frac{1}{n}$​

第 $i$​ 次取到任何数的概率均为 $\frac{1}{n}$​，取数的平均期望为 $\frac{n+1}{2}$​，故取 m 次的期望为 $\frac{m(n+1)}{2}$​。

## 马尔科夫链/马尔科夫过程

把状态想成一个图，当前状态仅与其直接连边的状态有关，即以当前状态为起点，深度为1的点决定当前状态。知乎有一哥们的理解：马尔科夫链上的节点仅需一层的历史状态就可以确定当前状态值，而不是必须由至少两层以上的历史状态决定。

在 dp 中，马尔科夫链上状态$i$​​对应的一层历史状态集合 $\{j\}$ ​​可能包含 $i$​​​，即自己，在图上表示成自环。有环先尝试移项。不能移项先往下看、、

## 随机游走

### 链上随机游走

利用期望的线性性，从 1 走到 n 的期望步数

$=\sum\limits_{i=1}^{n-1}E\{从i走到i+1的期望步数\}$​​

设 +1 的概率为 p，-1 的概率为 q，则$f[i] = p * 1 + q * (f[i-1] + f[i] + 1)$​

### 完全图上游走

从一个点 u 走到另一个点 v 的期望步数。

每次游走时，到v的概率都是 $\frac{1}{n-1}$​​，故期望为 $n-1$​​。

### 2n二分完全图上游走

从一个点 u 走到另一个点 v 的期望步数。

分同侧 A 的期望步数和异侧 $B$​ 的期望步数:

$B = \frac{1}{n}*1 + \frac{n-1}{n}*A$
$A = 1 + B$

解方程得 $B = n,A = n + 1$​

### n个点构成的菊花树（图）上游走

设叶子到叶子的期望 A，叶子到中心的期望为 1，中心到叶子为 B：

$B = \frac{1}{n-1}*1 + \frac{n-2}{n-1}*(A+1)$
$A = B + 1$

$B=1+2(n-2)=2n-3,A = 2n - 2$

### 树上随机游走的期望

$u->v$.

将 $v$​​​​​ ​当做根节点，令 $f(x)$​​​​ ​​为 $x$​​​​ ​​到 $x$​​​ ​​​的父亲 $fa$​​ ​​​​节点的期望步数，
$d(x)$​ ​​​​​为 $x$ ​​​​​​的度数：

$f(x) = \frac{1}{d(x)} + \frac{1}{d(x)}\sum\limits_{v\in son}(f(v)+f(x)+1)\Rightarrow f(x) = 1 + \sum\limits_{v\in son}(f(v)+1)$

若是求根到所有点的期望步数，求出所有$f(x)$后$O(n)$求和。

### 构造200个点的无向图使期望>=1000000

完全图加一条链。

S 代表链上的第一个点，先计算其值：

令 n = 100，在完全图中一点 u 到另外一点 v 的期望步数 $B:n-1$​

$f(1) = \frac{1}{n} + \frac{n-1}{n}(B+f(1)+1)\Rightarrow f(1) = n^2-n+1$

后面的

$f(i) = \frac{1}{2} + \frac{1}{2}(f(i-1)+f(i)+1)\Rightarrow f(i) = 2 + f(i-1)$​

则 f(100) 可达 $O(n^3)$​​

## 经典问题

### 凑齐1~n的期望

利用期望的线性性，

$EX = \sum\limits_{i=1}^{n} EX_i,X_i=\{凑到第i个数的次数\}$​

$EX_i = \frac{n}{n-i+1},EX = \frac{n^n}{n!}$

### 随机一个排列，问[1,i]中i代表的数最大的概率

首先，i 后面的数不影响结果。

划分成两部分，为 $[1,i],[i+1,n].$ ​由于全排列 $A_n^n = C_n^i*A_i^i*A_{n-i}^{n-i}$​，那么随机一个排列的过程可以看做挑$i$​个数先放入区间 $[1,i]$ ​中，再（这部分就不用考虑了）给 [i+1,n] 排列。

被放到 [1,i] 里的数有明确的大小关系，映射成 $1\sim i$​，那么第 $i$ ​位即最后一位的概率即为 $\frac{(i-1)!}{i!}=1/i$​​.

### 上一问题中i的个数的平方的期望

同样，

$EX = EX_i,X_i=\{第i个数是不是前i个最大的，是(X=1)不是(X=0)\}$​

易得 $EX_i = 1/i$​

当然结果等于 $(\sum\limits_{i=1}^n \frac{1}{i})^2$​。

### 随机一个长度为n的排列p，问i在j后面的概率

$\frac{1}{2}$​。由于 i 与 j 地位相同，要不 i 在 j 前面，要不 j 在 i 前面，故为 $\frac{1}{2}$​。$i=j$，概率为 $0$​​。

### 随机一个长度为n的排列p，问其包含w[1,m]的子序列的概率

$A_n^n = C_n^m*A_m^m*A_{n-m}^{n-m}$​，在这可以理解成给序列 w 的元素挑 m 个位置全排列，剩下元素全排列。可以看到只有 $\frac{1}{m!}$​​ 的概率可以包含 w。

### n堆石堆随机挑1石子扔一石堆，第一堆在被扔的期望

一次随机事件，石堆 $1\sim n$ ​被扔有明显次序。

记事件 $A_i = \{第i堆石堆被扔的轮数\}$​

则 $A_1 = \sum\limits^{n}_{i=1}[A_i<=A_1]$​

$EA_1 = E(\sum\limits^{n}_{i=1}[A_i<=A_1])$

其中 $E[A_i<=A_1] = P(A_i<=A_1) = \frac{a_i}{a_i+a_1}$，​由于当第 i 堆与第 1 堆都没被选的时候，决定被选的次序仅跟 $a_i$ ​与 $a_1$​ 的比例有关。

故 $EA_1 = 1 + \sum\limits^{n}_{i=2}\frac{a_i}{a_i+a_1}$​

### 01串1出现的概率为p，求串上连续1的长度平方之和的期望

dp + 概率。设 $ dp[i]$​​ 为前 i 个的答案的期望，$g[i]$​​ 为以 $i$​​ 结尾的连续 1 的长度的期望。

$A_{i+1}=\{i+1位为1\}=f[i+1] = f[i] - g[i]^2 + (g[i]+1)^2 = f[i]+ 2g[i] + 1,g[i+1] = g[i] + 1$

$\overline{A_{i+1}}=\{i+1位为0\}=f[i+1] = f[i],g[i+1] = 0$

故

$f[i+1] = p * (f[i] + 2g[i] + 1) + (1 - p) * (f[i]) = f[i] + 2p*g[i] + p,g[i+1] = p * (g[i] + 1)$​

~~个人觉得事件$A_i,\overline{A_i}$构成了划分，故原理说的通、、带入p=1与p=0都是正确的、、~~

这个要从期望的平均意义去理解：在第 $i$​ ​位，以 $i$​​ 位结尾的 1 串的长度就是 $g[i]$​​，而 $f[i+1]$ ​​等于前面的期望 + 在 $i+1$ ​​​​位增加的期望值。故原理是期望的平均意义。

### 序列随即删除元素，问i与j相邻的概率

将删除的元素顺序视为一个排列，观察 $i\sim j$​ ​中的 j-i+1 个元素，想要 i 与 j 相邻，则在删除排列中 i 与 j 中的元素要在 i 和 j 之前。还是利用 $A_n^n = C^{i-j+1}_{n}A_{i-j+1}^{i-j+1}A_{n-i+j-1}^{n-i+j-1}$​​，先挑出给元素 [i,j] 们调位置，排列，再给剩下的排列。所有方案 = $(j-i+1)!$​​，合法方案 $=2(j-i-1)!$​​，所以概率 $p = \frac{2(j-i-1)!}{(j-i+1)!} = \frac{2}{(j-i+1)(j-i)}$​​

## 练习题

### 一排硬币，随机取一个，增加的价值为该硬币左右两侧的面值乘积

一排硬币，随机取一个，求增加的价值的期望。

由于取硬币增加价值的过程等价于两个原本不相邻的两个硬币相邻产生的价值期望，故用上面的解法：$EX = \sum\limits^{n-2}_{i=1}\sum\limits^{n}_{j=i+2}\frac{2w[i]w[j]}{(j-i+1)(j-i)}$

### 一排硬币，随机取两个，增加的价值为该两硬币之和，合并后放回去

求操作 n-1 次的价值期望。

有顺序无放回 + 期望的平均意义，f(i) 为前 i 次所获价值期望。

记 $sum = \sum\limits^{n}_{i=1}a_i$$f(i) = f(i-1) + \frac{sum}{n-i+1}+\frac{sum}{n-i+1},i<=n-1$​

写成求和式：$sum\sum\limits_{i=2}^{n}\frac{2}{i}$​

$\frac{sum}{n-i+1}$​​ 而不是 $\frac{sum}{n}$​​：每次合并后，取的数虽然变小了，但总价值sum不变，平均价值即期望会上升；若是抽奖原则，每次取出数量减少，总价值也会按比例减少，平均价值不变。

### 树上边随机添加，问<u,v>连通的添加次数期望

n 个点有 n-1 条边。设 <u,v> 路径上有 k 条边，则 $EX = 选k次选完的期望+选k+1次选完的期望+...$​​

则 $EX = \sum\limits^{n-1}_{i=k}\frac{C_{n-1-k}^{i-k}*k!*(n-1-i)!}{(n-1)!}$

### 1~n删除一个数及其约数，求删完次数的期望

@@依赖删除问题的套路：将依赖的做标记。

可以发现原问题的事件 $S = \sum\limits_{i=1}^{n}X_i,X_i=\{第i个被删除时是否带标记，不带则1，带则0\}$

所以 $ES = \sum\limits_{i=1}^{n}EX_i$​

其中 $EX_i = P(X_i的倍数仍在，删X_i) = \frac{1}{\lfloor\frac{n}{i}\rfloor}$

所以 $ES = \sum\limits^{n}_{i=1}\frac{1}{\lfloor\frac{n}{i}\rfloor}$

## 高斯消元

原理略。

求矩阵的秩，常数项全为零，对应的now-1值就是秩。

## 概率&期望dp

概率与期望dp大多由后继推前继，答案就是起点。原因后继一般好求。

举例子，有一游戏玩$n$轮，问第$0$轮初始状态为$st$时赢的胜率。最后一轮即第$n$轮处在$st'$赢的胜率能直接得出，满足条件的胜率为1，不满足的为0.一路往回推，第$0$轮$st$的胜率就求出来了。

若有环且局数不定，求概率/期望的话可以模拟1w轮（允许的话），or高斯消元。

概率期望与dp的桥梁：如果状态的数量级允许，概率&期望就可以考虑用dp来做。

## 一些题目

### CCPC－Wannafly & Comet OJ 夏季欢乐赛（2019）E.飞行棋!

有一个$k$面色子，等概率选到移动的步数。距离终点为$d$。若选到移动步数大于到终点距离，则会往回走。问走到终点的期望。

先考虑k步以内的期望：$f(i)$为离终点为$i$，到终点的期望。有

$f(1) = \frac{1}{k}(f(0)+f(1)+f(2)+...+f(k-1))+1$
$f(2) = \frac{1}{k}(f(0)+2f(1)+f(2)+...+f(k-2))+1$
$f(3) = \frac{1}{k}(f(0)+2f(1)+2f(2)+...+f(k-3))+1$
$\cdot\cdot\cdot$

观察式子，右侧分子项的项数均为$k-1$，左侧均只有一项，高度对称。故假设$f(1)=f(2)=...=f(k)=x$，获得一组解$f(1)=f(2)=...=f(k)=k$

由于$d$大，利用$f(i) = \frac{1}{k}(f(i-1)+f(i-2)+...+f(i-k))+1$，套$(n+1)x(n+1)$矩阵的快速幂即得出答案。待乘项为$[f(1),f(2),...,f(k),1]^T$。一项都不能漏。

## 牛客小白月赛16 I.石头剪刀布

随机游走问题。

利用期望的线性性，构建期望线性模型：

事件$X=\{走到n格的步数\}，则EX=E\{从第一格走到第二格的步数\}+E\{从第二格走到第三格的步数\}+...+E\{从第n-1格走到第n格的步数\}$

此时$f[i] = a * 1 + b * (f[i] + 1) + (1 - a - b) * (f[i-1] + f[i] + 1),\\
f[1] = a * 1 + (1 - a) * (f[1] + 1)$

答案即为$\sum\limits_{i=1}^{n-1}f[i]$.

### CodeForces 148D Bag of mice

有w只白鼠&b个黑鼠。A和B轮流随机抓一只鼠，第一个抓到白鼠的赢。特殊的是当B抓完一只鼠后从袋子里又随机跑出另一只鼠，这只鼠不属A或B。袋子空了，B获胜。问A的期望胜率。

由于$w*b$的数量级允许，故用$f(i,j)$表示还有$i$个白鼠$j$个黑鼠A赢的胜率。

> * 轮到A时：
> $i = 0$,则胜率为0
> $i \ != 0, j = 0，则胜率为1$
> 该轮赢的概率为$\frac{i}{i+j},(1)$
> 下若干轮赢的概率：
>> A黑，B黑，跑黑：$p_1 * p_2 * p_3 * f(i,j-3),(2)$
>> A黑，B黑，跑白：$p_1 * p_2 * p_3' * f(i-1,j-2),(3)$

将概率$(1),(2),(3)$加起来就是$f(i,j)$的答案。

### CodeForces 540D	Bad Luck Island

三个物种对应石头r剪刀s布p。在岛上随机两个物种pk，被克的一方死亡。问三个物种存留岛上的期望概率。

用dp(ani,i,j,k)代表物种ani在有i石头j剪刀p布的生存概率。

先看只有1种or只有两种物种的情况：

当只有一种物种且物种为ani，则生存概率为1；否则为0。
当只有两种物种且ani克另一物种，则生存概率为1；否则为0。

当三个物种都存在，按超几何分布计算挑出不同两个物种的概率，记得除去对应的占比（因为不考虑挑出同个物种，概率总和 < 1），由对应的$dp'$转移而来即可。

### CodeForces 912D	Fishes

有$n * m$大小的鱼塘分成$n*m$个小格，每个小格至多放一条鱼。有一$r*r$大小的网随机往鱼塘捕，要求网覆盖鱼塘。有k条鱼，问如何摆放鱼使随机捕的鱼数量期望最大。

思维转化，计算等概率的网捕获鱼的期望等价于每个格子被网网住的次数*概率，然后挑被覆盖次数最多的格子放鱼。

同样动用思维，将两维拆成一维的角度即m取r，看n改变对应的矩阵覆盖的变化(打表)。发现从上到下成对称梯形$1,2,...,f(\frac{n}{2}),f(\frac{n}{2}),...,1$

将一维扩成2维，发现是由第一列依次成倍数（倍数也是对称梯形）得来的第2列第三列...那么覆盖次数的集合就来自$<1,2,...,R1>\times<1,2,...,R2>,R1,R2$分别为第一列最大的数和第一行最大的数。取前面最大的，则用优先队列来做。

### CodeForces 678E	Another Sith Tournament

~~翻车，两次没读懂题~~

选手1~n，有配备的胜负表。选手1可操控全场互殴顺序，并可安排另外的去替补被打败的。问选手1的最大胜率。

这样反而好写。$f(st,j)$表示当前在位选手集$st$，擂主为$j$的最大胜率。轻松写出$f(st,j) = P(j\ pk\ k) * f(st^k,k) + P(k\ pk\ j) * f(st^j,j)$。开头则要O(n^2)选两名比赛选手。复杂度为$O(n^2*2^n)$

### HDU 6507 Store The Matrix

一个矩阵A可以表示成$A = A_1 * A_2 * ... * A_n,n>=1$，其所占空间为$\sum\limits_{i=1}^{n}r_i*c_i$。

问合法$A_1 * A_2 * ... * A_n$的最小所占空间。

观察到矩阵$r*h,h*c$可以构成A矩阵。$h$能取多小取决于？当h为1的时候，第i行只是第一行的若干倍。当h为2时，至多可以构造不成比例的两行。联系矩阵的秩：求出原矩阵的秩$rank$，则用$[r*h]*[h*c],h=rank$方式所占空间为$rank*(r+c)$，跟$r*c$取较小值得答案。

### HihoCoder 1166 Commutative Algebra

现在有个长度为n的01石子，每次随机选择一个区间(共$\frac{n(n+1)}{2}$个)将0置1,1置0。问所有棋子变为0的期望步数。

区间反转，~~很容易~~想到差分。让区间变为$a_0,a_1,...,a_{n+1},a_0=a_{n+1}=0$令$d[i] = a[i] - a[i+1]$，则最后让所有$d[i]=0$时等价于整个区间为0。注意到所有区间翻转仅改变两个值。记$cnt_i$为有$i$个1的区间情况，可以发现$cnt_i$的所有情况都是等价的，即$P(cnt_i->cnt_{i-2}),P(cnt_i->cnt_{i}),P(cnt_i->cnt_{i+2})$都是相等的（在计算概率时顺序改变而已）。故问题的状态只有$cnt_0,cnt_2,cnt_4,...,O(n)$个状态。

在用高斯定理的时候，不用那么多特判，限定一下列col，即限定变量个数，最后再填常数项，节约时间、、

### CodeForces 280C	Game on Tree

随机删除的套路、、当删除一个点，将所影响的点打上标记。

则问题的期望$EX = \sum\limits_{i=1}^{n}EX_i,X_i = \{i删的时候没被标记为1，被标记为0\}$

$i$没被标记的期望等于没被标记的概率，$i$删的时候没被标记，意味自己及其祖先节点都没被删，故概率为$\frac{1}{d[i]}$。

所以$EX = \sum\limits_{i=1}^{n}\frac{1}{d[i]}$

### Ant [HDU - 6788]

概率dp。由于第二只蚂蚁必须沿着第一只蚂蚁留下的信号素and自己没走过的路等概率游走，故第一只蚂蚁必须走到石榴M且停下来。1->M的路径上是单向边，其余的分支为双向边。长出一个分支，直接由1->M的最短路方案就变为$\frac{1}{2}$,故第一个蚂蚁的路径至多叉出一条分叉。$dp[i][0]$为走到当前$i$点，还没走过分叉的概率；$dp[i][1]$为走到当前$i$点，分叉过一次的概率、、

### 计蒜客Random Access Iterator

设计$dp[i]$为以节点$i$为根节点，能一次走到最底层的概率。考虑反问题，在$i$节点一次不能走到最底层的概率$cal = 1 - \sum\limits_{v\in u}\frac{dp[v]}{deg}$,则$dp[u] = 1 - cal^{deg}$、、

### CF113D Museum

令$dp(u,v)$为从$(a,b)$出发，到$(u,v)$的 **期望次数** 。那么可以列出方程：
$$
dp(u,v) = p_up_vdp(u,v) + \frac{1-p_u}{deg_u}p_vdp(u',v) + \frac{1-p_v}{deg_v}p_udp(u,v') + \frac{1-p_v}{deg_v}\frac{1-p_u}{deg_u}dp(u',v')
$$
边界情况为
$$
dp(a,b) = p_ap_bdp(a,b) + \frac{1-p_a}{deg_a}p_bdp(a',b) + \frac{1-p_b}{deg_b}p_adp(a,b') + \frac{1-p_b}{deg_b}\frac{1-p_a}{deg_a}dp(a',b') + 1
$$
由于一开始就在$(a,b)$。

另外当前状态不能由中止状态$dp(c,c)$转移而来，注意这一点。

由于中止状态由状态集$(c,c)$划分，故中止状态的 **期望次数** = **以该点结束的期望概率** 。

### P4206 [NOI2005]聪聪与可可

由于图是边权为1的，故$O(n^2)$能bfs出所有点对的最短距离。预处理出处在状态$(C,M)$时猫会往哪走。

由于每单位时间，猫与鼠的距离必然会缩短，故直接记忆化搜索就行。

### P3232 [HNOI2013]游走

计算边的期望经过次数比较麻烦，考虑计算点的。

由Museum的思路轻松计算出各个点的 **期望经过次数** 。对于每条边的期望经过次数则是$\frac{p_u}{deg_u} + \frac{p_v}{deg_v}$。排下序就行。